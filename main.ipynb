{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60055, 5)\n",
      "(29266, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\croco\\AppData\\Local\\Temp\\ipykernel_5352\\3075150544.py:3: DtypeWarning: Columns (20,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dbfile = pd.read_csv('./Data/VDJDB/vdjdb_full.txt', sep='\\t')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdr3.alpha</th>\n",
       "      <th>cdr3.beta</th>\n",
       "      <th>antigen.epitope</th>\n",
       "      <th>antigen.species</th>\n",
       "      <th>mhc.class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIVRAPGRADMRF</td>\n",
       "      <td>CASSYLPGQGDHYSNQPQHF</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>MHCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAVPSGAGSYQLTF</td>\n",
       "      <td>CASSFEPGQGFYSNQPQHF</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>MHCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAVKASGSRLT</td>\n",
       "      <td>CASSYEPGQVSHYSNQPQHF</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>MHCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAYRPPGTYKYIF</td>\n",
       "      <td>CASSALASLNEQFF</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>MHCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CIVRAPGRADMRF</td>\n",
       "      <td>CASSYLPGQGDHYSNQPQHF</td>\n",
       "      <td>FLKEQGGL</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>MHCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cdr3.alpha             cdr3.beta antigen.epitope antigen.species  \\\n",
       "0   CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEKGGL           HIV-1   \n",
       "2  CAVPSGAGSYQLTF   CASSFEPGQGFYSNQPQHF        FLKEKGGL           HIV-1   \n",
       "3     CAVKASGSRLT  CASSYEPGQVSHYSNQPQHF        FLKEKGGL           HIV-1   \n",
       "4   CAYRPPGTYKYIF        CASSALASLNEQFF        FLKEKGGL           HIV-1   \n",
       "5   CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEQGGL           HIV-1   \n",
       "\n",
       "  mhc.class  \n",
       "0      MHCI  \n",
       "2      MHCI  \n",
       "3      MHCI  \n",
       "4      MHCI  \n",
       "5      MHCI  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load dataset & filter out missing data\n",
    "# dbfile = pd.read_csv('./Data/vdjdb.slim.txt', sep='\\t')\n",
    "dbfile = pd.read_csv('./Data/VDJDB/vdjdb_full.txt', sep='\\t')\n",
    "# print(dbfile.columns)\n",
    "dbfile = dbfile[['cdr3.alpha', 'cdr3.beta','antigen.epitope','antigen.species',\"mhc.class\"]]\n",
    "print(dbfile.shape)\n",
    "dbfile = dbfile.dropna(subset=['cdr3.alpha', 'cdr3.beta','antigen.epitope'])\n",
    "print(dbfile.shape)\n",
    "dbfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\croco\\AppData\\Local\\Temp\\ipykernel_5352\\605436328.py:1: DtypeWarning: Columns (8,10,11,13,15,16,17,18,19,20,21,22,23,24,25,30,31,36,37,42,44,45,46,47,48,49,50,51,52,53,54,59,60,65,66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  iedbfile = pd.read_csv('./Data/IEDB/tcell_receptor_table_export_1668026760.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205824, 4)\n",
      "(25927, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chain 1 CDR3 Curated</th>\n",
       "      <th>Chain 2 CDR3 Curated</th>\n",
       "      <th>Description</th>\n",
       "      <th>Organism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IVVRSSNTGKLI</td>\n",
       "      <td>ASSQDRDTQY</td>\n",
       "      <td>VMAPRTLIL</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>CAVTTDSWGKLQF</td>\n",
       "      <td>CASRPGLAGGRPEQYF</td>\n",
       "      <td>LLFGYPVYV</td>\n",
       "      <td>Human T-cell leukemia virus type I (Human T ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>CAVTTDSWGKLQF</td>\n",
       "      <td>CASRPGLMSAQPEQYF</td>\n",
       "      <td>LLFGYPVYV</td>\n",
       "      <td>Human T-cell leukemia virus type I (Human T ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>CAVRPTSGGSYIPTF</td>\n",
       "      <td>CASSYVGNTGELFF</td>\n",
       "      <td>SLLMWITQC</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>TVYGGATNKLI</td>\n",
       "      <td>SARGGSYNSPLH</td>\n",
       "      <td>LSRFSWGAEGQRPGFGYGG</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Chain 1 CDR3 Curated Chain 2 CDR3 Curated          Description  \\\n",
       "0           IVVRSSNTGKLI           ASSQDRDTQY            VMAPRTLIL   \n",
       "80         CAVTTDSWGKLQF     CASRPGLAGGRPEQYF            LLFGYPVYV   \n",
       "82         CAVTTDSWGKLQF     CASRPGLMSAQPEQYF            LLFGYPVYV   \n",
       "109      CAVRPTSGGSYIPTF       CASSYVGNTGELFF            SLLMWITQC   \n",
       "202          TVYGGATNKLI         SARGGSYNSPLH  LSRFSWGAEGQRPGFGYGG   \n",
       "\n",
       "                                              Organism  \n",
       "0                                 Homo sapiens (human)  \n",
       "80   Human T-cell leukemia virus type I (Human T ce...  \n",
       "82   Human T-cell leukemia virus type I (Human T ce...  \n",
       "109                               Homo sapiens (human)  \n",
       "202                               Homo sapiens (human)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iedbfile = pd.read_csv('./Data/IEDB/tcell_receptor_table_export_1668026760.csv')\n",
    "# print(iedbfile.columns)\n",
    "# Chain 1 Full Sequence', 'Chain 1 Accession', 'Chain 1 CDR3 Curated',\n",
    "#        'Chain 1 CDR3 Calculated'\n",
    "iedbfile = iedbfile[['Chain 1 CDR3 Curated','Chain 2 CDR3 Curated',\"Description\",\"Organism\"]]\n",
    "print(iedbfile.shape)\n",
    "iedbfile = iedbfile.dropna(subset=['Chain 1 CDR3 Curated','Chain 2 CDR3 Curated',\"Description\"])\n",
    "iedbfile.Description = iedbfile.Description.str.split(' ').str[0]\n",
    "iedbfile = iedbfile[~iedbfile.Description.str.contains('[^ARNDCQEGHILKMFPSTWYV]',na=False)]\n",
    "print(iedbfile.shape)\n",
    "iedbfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixeddb = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding & split sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import load\n",
    "# from functions.load import enc_list_bl_max_len, positional_coding, blosum50_20aa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions.load' from 'c:\\\\Users\\\\croco\\\\OneDrive - Emory University\\\\Courses\\\\BMI 536 Deep Learning\\\\FinalProj\\\\functions\\\\load.py'>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from importlib import reload\n",
    "reload(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     CIVRAPGRADMRF\n",
      "2    CAVPSGAGSYQLTF\n",
      "Name: cdr3.alpha, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 30, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dbfile.head(n=2)[\"cdr3.alpha\"])\n",
    "load.enc_list_bl_max_len(dbfile.head(n=2)[\"cdr3.alpha\"],load.blosum50_20aa,30).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load.blosum50_20aa.keys()\n",
    "\n",
    "tokens = list(tokens)\n",
    "tokens.insert(0, '.')\n",
    "tokens.insert(1, '>')\n",
    "tokens.insert(2, '<')\n",
    "tk_dict = defaultdict(lambda: None)\n",
    "for idx in range(len(tokens)):\n",
    "    tk_dict[tokens[idx]]=idx\n",
    "vocabSize=23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 30)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load.positional_coding(dbfile.head(n=52)[\"cdr3.alpha\"],tk_dict,30).shape\n",
    "load.positional_coding(iedbfile.head(n=52)[\"Chain 1 CDR3 Curated\"],tk_dict,30).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dbfile[dbfile['antigen.epitope'].str.len()<=12], shuffle=True ,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7., 12., 22.,  4.,  3., 17., 10.,  4.,  3.,  6., 15.,  4., 16.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  7.,  3., 18., 18., 21., 13., 17., 10.,  8.,\n",
       "       10.,  6., 11., 21., 18.,  5.,  8., 17.,  8., 11., 16.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(load.positional_coding((\"CIVRAPGRADMRF\",\"CASSYLPGQGDHYSNQPQHF\"), tk_dict, 30)) #CIVRAPGRADMRF\tCASSYLPGQGDHYSNQPQHF\tFLKEKGGL\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23161, 13) (23161, 30) (23161, 30) (23161, 60)\n"
     ]
    }
   ],
   "source": [
    "ept_train = load.ept_coding(train['antigen.epitope'], tk_dict, 13,train=True)\n",
    "tcra_train = load.positional_coding(train[\"cdr3.alpha\"], tk_dict, 30)\n",
    "tcrb_train = load.positional_coding(train[\"cdr3.beta\"], tk_dict, 30)\n",
    "# ept_train = np.roll(ept_train, 1)\n",
    "ept_train_lb = load.ept_coding(train['antigen.epitope'], tk_dict, 13,label=True)\n",
    "tcr_train = np.concatenate((tcra_train,tcrb_train),axis=1)\n",
    "print(ept_train.shape, tcra_train.shape, tcrb_train.shape,tcr_train.shape)\n",
    "ept_test = load.ept_coding(test['antigen.epitope'], tk_dict, 13,train=True)\n",
    "tcra_test = load.positional_coding(test[\"cdr3.alpha\"], tk_dict, 30)\n",
    "tcrb_test = load.positional_coding(test[\"cdr3.beta\"], tk_dict, 30)\n",
    "tcr_test = np.concatenate((tcra_test,tcrb_test),axis=1)\n",
    "# ept_train = np.roll(ept_train, 1)\n",
    "ept_test_lb = load.ept_coding(test['antigen.epitope'], tk_dict, 13,label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_train = tf.convert_to_tensor(tcr_train)\n",
    "ept_train = tf.convert_to_tensor(ept_train)\n",
    "ept_train_lb = tf.convert_to_tensor(ept_train_lb)\n",
    "tcr_test = tf.convert_to_tensor(tcr_test)\n",
    "ept_test = tf.convert_to_tensor(ept_test)\n",
    "ept_test_lb = tf.convert_to_tensor(ept_test_lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import model\n",
    "# reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "MAX_TOKENS = 32\n",
    "\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(((tcr_train,ept_train),ept_train_lb))\n",
    "dataset = make_batches(dataset)\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices(((tcr_test, ept_test),ept_test_lb))\n",
    "dataset_val = make_batches(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60)\n",
      "(64, 13)\n",
      "(64, 13)\n"
     ]
    }
   ],
   "source": [
    "for (tcr, ept), ept_lb in dataset.take(2):\n",
    "  break\n",
    "\n",
    "print(tcr.shape)\n",
    "print(ept.shape)\n",
    "print(ept_lb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1. 19. 18.  3. 15.  8. 19. 15. 13. 16.  0.  0.  0.], shape=(13,), dtype=float64)\n",
      "tf.Tensor([19. 18.  3. 15.  8. 19. 15. 13. 16.  2.  0.  0.  0.], shape=(13,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(ept[0])\n",
    "print(ept_lb[0])\n",
    "\n",
    "embed_tcr = model.PositionalEmbedding(vocab_size=vocabSize, d_model=512)\n",
    "embed_ept = model.PositionalEmbedding(vocab_size=vocabSize, d_model=512)\n",
    "\n",
    "tcr_emb = embed_tcr(tcr)\n",
    "ept_emb = embed_ept(ept)\n",
    "# print(tcr_emb._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60)\n",
      "(64, 60, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = model.Encoder(num_layers=4,\n",
    "                         d_model=512,\n",
    "                         num_heads=8,\n",
    "                         dff=2048,\n",
    "                         vocab_size=vocabSize)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tcr, training=False)\n",
    "print(tcr.shape)\n",
    "print(sample_encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = model.Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=np.int64(vocabSize),\n",
    "    target_vocab_size=np.int64(vocabSize),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60)\n",
      "(64, 13)\n",
      "(64, 13, 23)\n",
      "(64, 8, 13, 60)\n"
     ]
    }
   ],
   "source": [
    "output = transformer((tcr, ept))\n",
    "\n",
    "print(tcr.shape)\n",
    "print(ept.shape)\n",
    "print(output.shape)\n",
    "\n",
    "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
    "print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output[1,1,:]\n",
    "# ept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = model.CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "# plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "# plt.ylabel('Learning Rate')\n",
    "# plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=model.masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[model.masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_10 (Encoder)        multiple                  2641792   \n",
      "                                                                 \n",
      " decoder_4 (Decoder)         multiple                  4752768   \n",
      "                                                                 \n",
      " dense_132 (Dense)           multiple                  2967      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,397,527\n",
      "Trainable params: 7,397,527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "362/362 [==============================] - 33s 73ms/step - loss: 1.4906 - masked_accuracy: 0.6144 - val_loss: 0.7131 - val_masked_accuracy: 0.8282\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 25s 69ms/step - loss: 0.5786 - masked_accuracy: 0.8572 - val_loss: 0.4575 - val_masked_accuracy: 0.8841\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 25s 69ms/step - loss: 0.4241 - masked_accuracy: 0.8923 - val_loss: 0.3852 - val_masked_accuracy: 0.9007\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3752 - masked_accuracy: 0.9038 - val_loss: 0.3597 - val_masked_accuracy: 0.9075\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3526 - masked_accuracy: 0.9091 - val_loss: 0.3421 - val_masked_accuracy: 0.9145\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3403 - masked_accuracy: 0.9124 - val_loss: 0.3378 - val_masked_accuracy: 0.9132\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 26s 70ms/step - loss: 0.3347 - masked_accuracy: 0.9135 - val_loss: 0.3398 - val_masked_accuracy: 0.9135\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3368 - masked_accuracy: 0.9128 - val_loss: 0.3366 - val_masked_accuracy: 0.9141\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 25s 69ms/step - loss: 0.3427 - masked_accuracy: 0.9112 - val_loss: 0.3477 - val_masked_accuracy: 0.9107\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 26s 71ms/step - loss: 0.3781 - masked_accuracy: 0.9009 - val_loss: 0.3912 - val_masked_accuracy: 0.8998\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3867 - masked_accuracy: 0.8978 - val_loss: 0.3938 - val_masked_accuracy: 0.8967\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3896 - masked_accuracy: 0.8969 - val_loss: 0.3852 - val_masked_accuracy: 0.8987\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3835 - masked_accuracy: 0.8979 - val_loss: 0.3808 - val_masked_accuracy: 0.8995\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3780 - masked_accuracy: 0.8993 - val_loss: 0.3780 - val_masked_accuracy: 0.9013\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3690 - masked_accuracy: 0.9022 - val_loss: 0.3779 - val_masked_accuracy: 0.9009\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3629 - masked_accuracy: 0.9033 - val_loss: 0.3745 - val_masked_accuracy: 0.9022\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3567 - masked_accuracy: 0.9050 - val_loss: 0.3714 - val_masked_accuracy: 0.9033\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3526 - masked_accuracy: 0.9060 - val_loss: 0.3640 - val_masked_accuracy: 0.9043\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 25s 70ms/step - loss: 0.3474 - masked_accuracy: 0.9075 - val_loss: 0.3613 - val_masked_accuracy: 0.9057\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 25s 69ms/step - loss: 0.3431 - masked_accuracy: 0.9085 - val_loss: 0.3572 - val_masked_accuracy: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29fa6ef5b50>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(dataset,\n",
    "                epochs=20,\n",
    "                validation_data=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions.model' from 'c:\\\\Users\\\\croco\\\\OneDrive - Emory University\\\\Courses\\\\BMI 536 Deep Learning\\\\FinalProj\\\\functions\\\\model.py'>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = model.Translator(tk_dict, tokens, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, ground_truth):\n",
    "  print(f'{\"Input:\":15s}: {sentence}')\n",
    "  print(f'{\"Prediction\":15s}: {tokens}')\n",
    "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : ('CIVRAPGRADMRF', 'CASSYLPGQGDHYSNQPQHF')\n",
      "Prediction     : ['>KLGGALQAK<<<']\n",
      "Ground truth   : FLKEKGGL\n"
     ]
    }
   ],
   "source": [
    "sentence = (\"CIVRAPGRADMRF\",\"CASSYLPGQGDHYSNQPQHF\")\t\t\n",
    "ground_truth = \"FLKEKGGL\"\n",
    "\n",
    "translated_text, attention_weights = translator(sentence)\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as positional_embedding_32_layer_call_fn, positional_embedding_32_layer_call_and_return_conditional_losses, dropout_134_layer_call_fn, dropout_134_layer_call_and_return_conditional_losses, positional_embedding_33_layer_call_fn while saving (showing 5 of 316). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mdl_vdj_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mdl_vdj_1\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(transformer, \"models/mdl_vdj_1\")\n",
    "# model = tf.saved_model.load(\"models/mdl_vdj_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "009932425255c51b26de204d40c57b9ea5b32c204f45def90e769b2261880a6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
